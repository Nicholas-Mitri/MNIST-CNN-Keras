{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CLASSIFICATION WITH CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we leverage the simplicity and ease of modeling offered by Keras to create a CNN for the classification of hand-written digits from the popular MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tensorflow, numpy, matplotlib, as well as the sequential model from Keras and the layer types we will be using to build the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST Dataset from Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras offers a collection of datasets through its datasets module. That provides an easy way for us to download and load a partitioned version of MNIST with 60,000 training examples and 10,000 testing examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape and normalize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras 2D convolutional layers require the input data to be 4D (data size, rows, cols, channels). The data is therefore reshaped accordingly. Also, as common practice, we normalize the data from the 0-255 range to 0-1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_train /= 255 #normalize\n",
    "\n",
    "x_test = x_test.astype(np.float32)\n",
    "x_test /= 255 #normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is built using Keras' Sequential model. For this example, a simple model consisting of a single convolutional layer followed by pooling, flattening, and a single hidden layer DNN is utilized. The output of the DNN is a softmax dense layer.\n",
    "A dropout layer with a drop rate of 20% is used to counter overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=(28,28,1), activation=tf.nn.relu, name='Conv1'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, name='maxpool1'))\n",
    "model.add(Flatten(name='flatten')) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu, name='Dense1'))\n",
    "model.add(Dropout(0.2, name='Dropout'))\n",
    "model.add(Dense(10,activation=tf.nn.softmax, name='Dense2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1 (Conv2D)               (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4732)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               605824    \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 607,394\n",
      "Trainable params: 607,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 22s 372us/step - loss: 0.0338 - acc: 0.9901\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0274 - acc: 0.9921\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0224 - acc: 0.9935\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0184 - acc: 0.9947\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 22s 369us/step - loss: 0.0149 - acc: 0.9959\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0123 - acc: 0.9968\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0108 - acc: 0.9974\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 22s 368us/step - loss: 0.0090 - acc: 0.9979\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0072 - acc: 0.9986\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 22s 368us/step - loss: 0.0066 - acc: 0.9987\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.0051 - acc: 0.9992\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 22s 362us/step - loss: 0.0040 - acc: 0.9995\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 22s 369us/step - loss: 0.0037 - acc: 0.9994\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 22s 362us/step - loss: 0.0034 - acc: 0.9994\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 22s 367us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 22s 369us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 22s 367us/step - loss: 0.0013 - acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x288298062b0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, batch_size=500, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label is 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = np.random.randint(0,10000)\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print('Predicted label is', pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final model achieves 98.62% accuracy on the test partition.\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred_label = np.argmax(pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test, pred_label)\n",
    "print('The final model achieves {:04.2f}% accuracy on the test partition.'.format(acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
